{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assingment 4 Testing and Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H(s)= - \\sum_{i, j} J_{i, j} * s_i * s_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step: load in data and interpret '+' and '-' as +1 and -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  1., -1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.],\n",
       "       [ 1., -1.,  1.,  1.],\n",
       "       ...,\n",
       "       [ 1.,  1.,  1.,  1.],\n",
       "       [ 1., -1.,  1.,  1.],\n",
       "       [-1.,  1., -1., -1.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "ass_dir = cwd.rsplit('\\\\', maxsplit=1)[0]\n",
    "\n",
    "#import\n",
    "pm_data_str = np.loadtxt(os.path.join(ass_dir, r'data\\in.txt'), dtype=str)\n",
    "\n",
    "# separate string into characters\n",
    "pm_data_sep = np.empty((pm_data_str.shape[0], len(pm_data_str[0])), dtype=str)\n",
    "for i in range(len(pm_data_str)):\n",
    "    pm_data_sep[i] = list(pm_data_str[i])\n",
    "\n",
    "# locations of plus minus\n",
    "p_loc = np.where(pm_data_sep == '+')\n",
    "m_loc = np.where(pm_data_sep == '-')\n",
    "\n",
    "# convert plus/minus to +1/-1\n",
    "pm_data = np.empty(pm_data_sep.shape)\n",
    "pm_data[p_loc] = 1.\n",
    "pm_data[m_loc] = -1.\n",
    "pm_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole layout of this assignment is as follows:\n",
    "1. Build Ising model that has a $\\lambda_{i,j}$ which is the weights between nearest neighbours\n",
    "2. Randomly (seeded) generate intial weights between -1 and 1 based on the size of Ising model (N weights for N atoms)\n",
    "3. Use model to generate as many smaples as there are in the in.txt\n",
    "4. Use model outputs and in.txt to compute gradient as follows:\n",
    "$$\n",
    "-\\frac{\\partial}{\\partial \\lambda_{i,j}} Loss (\\lambda) = <s_i s_j>_D - <s_i s_j>_\\lambda\n",
    "$$\n",
    "Where $s_i$ is the spin at particular location and you are averaging over the whole data set and generated set\n",
    "5. Use the above gradient to update the weights of the model\n",
    "6. Repeat steps 3-5 until model reaches the correct weights, $L$\n",
    "\n",
    "\n",
    "Next we'll calcualte the average across the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({(0, 1): -0.54, (1, 2): 0.466, (2, 3): 0.436, (3, 0): 0.454},\n",
       " array([-0.54 ,  0.466,  0.436,  0.454]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avg_coupler(pm_data):\n",
    "    data_avg_dict = {}\n",
    "    data_avg_arr = np.empty(pm_data.shape[1])\n",
    "\n",
    "    for j in range(pm_data.shape[1]):\n",
    "        if j != pm_data.shape[1] - 1:\n",
    "            data_avg_dict[(j, j+1)] = np.average(pm_data[:, j] * pm_data[:, j+1])\n",
    "            data_avg_arr[j] = data_avg_dict[(j, j+1)]\n",
    "        else:\n",
    "            data_avg_dict[(j, 0)] = np.average(pm_data[:, j] * pm_data[:, 0])\n",
    "            data_avg_arr[j] = data_avg_dict[(j, 0)]\n",
    "\n",
    "    return data_avg_dict, data_avg_arr\n",
    "avg_coupler(pm_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above roughly equals the {(0, 1): -1, (1, 2): 1, (2, 3): 1, (3, 0): 1} given to us as the true weights that produced the data set. This makes sense as those weights influence the monte carlo outputs. If it was truly random then we would expect ~0 for all.\n",
    "\n",
    "Now we need to implement a 1D Ising model of size N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current KL is 0.42 and weights are: [-0.83321063  0.26942744 -0.19599057  0.69203735]\n",
      "Current KL is 0.40 and weights are: [-0.97971063  0.47172744 -0.11519057  0.94323735]\n",
      "Current KL is 0.38 and weights are: [-1.          0.64762744 -0.05479057  1.        ]\n",
      "Current KL is 0.37 and weights are: [-1.          0.79672744  0.02110943  1.        ]\n",
      "Current KL is 0.40 and weights are: [-1.          0.92342744  0.09970943  1.        ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 136\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[39mreturn\u001b[39;00m num_equal\u001b[39m/\u001b[39mdata\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m    135\u001b[0m ising \u001b[39m=\u001b[39m Ising1D(pm_data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], pm_data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[1;32m--> 136\u001b[0m ising\u001b[39m.\u001b[39mtrain_weights(pm_data, \u001b[39m250\u001b[39m, \u001b[39m0.05\u001b[39m, flips_per_site\u001b[39m=\u001b[39m\u001b[39m25\u001b[39m)\n",
      "Cell \u001b[1;32mIn [3], line 75\u001b[0m, in \u001b[0;36mIsing1D.train_weights\u001b[1;34m(self, train_data, num_epochs, learning_rate, flips_per_site, verbose)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m     73\u001b[0m     \u001b[39m# generate lattices, go to equilibrium, and average couplers\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_lattices()\n\u001b[1;32m---> 75\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mequilibrium(flips_per_site\u001b[39m=\u001b[39;49mflips_per_site)\n\u001b[0;32m     76\u001b[0m     model_coupler_avg \u001b[39m=\u001b[39m avg_coupler(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlattices)\n\u001b[0;32m     78\u001b[0m     \u001b[39m# update weights \u001b[39;00m\n",
      "Cell \u001b[1;32mIn [3], line 52\u001b[0m, in \u001b[0;36mIsing1D.equilibrium\u001b[1;34m(self, flips_per_site)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlattices[i, j] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlattices[i, j] \u001b[39m*\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     50\u001b[0m \u001b[39mif\u001b[39;00m current \u001b[39m<\u001b[39m new:\n\u001b[0;32m     51\u001b[0m     \u001b[39m# using metropolis algorithm we sometimes take this option\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mrandom(\u001b[39m1\u001b[39;49m)[\u001b[39m0\u001b[39m] \u001b[39m<\u001b[39m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39m(new \u001b[39m-\u001b[39m current)):\n\u001b[0;32m     53\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlattices[i, j] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlattices[i, j] \u001b[39m*\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class Ising1D():\n",
    "    '''\n",
    "    1D Ising model class.\n",
    "    '''\n",
    "    def __init__(self, N, num_samples, seed=3141):\n",
    "\n",
    "        # set random seed for generating weights\n",
    "        np.random.seed(seed)\n",
    "        self.weights = np.random.uniform(low=-1., high=1., size=N)\n",
    "\n",
    "        self.N = N\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "        # setup the lattices\n",
    "        self.generate_lattices()\n",
    "        \n",
    "\n",
    "    def generate_lattices(self) -> np.ndarray:\n",
    "        '''Generates num_samples amount of 1D lattices of shape N'''\n",
    "        np.random.seed()\n",
    "        self.lattices = (np.random.randint(0, 2, size=(self.num_samples, self.N)) * 2) - 1\n",
    "\n",
    "    def equilibrium(self, flips_per_site=100):\n",
    "        '''\n",
    "        Lets each lattice go to equilibrium\n",
    "\n",
    "        Params\n",
    "        ---\n",
    "        flips_per_site - average number of flips per site\n",
    "        '''\n",
    "        tot_flips = self.N * flips_per_site # total number of flips\n",
    "\n",
    "        # random indices to attempt to flip\n",
    "        np.random.seed()\n",
    "        rand_j = np.random.randint(low=0, high=self.N, size=(self.num_samples, tot_flips))\n",
    "\n",
    "        # outer loop goes through each lattice, letting each go to equilibrium\n",
    "        for i in range(self.num_samples):\n",
    "\n",
    "            # loop through the random indices trying to flip\n",
    "            for j in rand_j[i, :]:\n",
    "                # calculate current and new energy at indice j\n",
    "                current, new = self.get_energy_difference(i, j)\n",
    "\n",
    "                # comparing energies\n",
    "                if current >= new:\n",
    "                    # keep spin if improved or stayed same\n",
    "                    self.lattices[i, j] = self.lattices[i, j] * -1\n",
    "\n",
    "                if current < new:\n",
    "                    # using metropolis algorithm we sometimes take this option\n",
    "                    if np.random.random(1)[0] < np.exp(-(new - current)):\n",
    "                        self.lattices[i, j] = self.lattices[i, j] * -1\n",
    "\n",
    "    def get_energy_difference(self, i, j):\n",
    "        '''Calculates and returns current and new energy at location j in lattice i'''\n",
    "\n",
    "        # sum contributions from adjacent spins\n",
    "        current = self.lattices[i, j] * self.lattices[i, j-1] * self.weights[j-1] * -1\n",
    "        current += self.lattices[i, j] * self.lattices[i, (1+j-self.N)] * self.weights[1+j-self.N] * -1\n",
    "        new = current * -1 # flipping of j is simply multiplying by negative 1\n",
    "\n",
    "        return current, new\n",
    "\n",
    "    def train_weights(self, train_data, num_epochs, learning_rate, flips_per_site=100,\n",
    "                      verbose = True):\n",
    "        '''\n",
    "        Trains weights based on data set\n",
    "        '''\n",
    "        train_coupler_avg = avg_coupler(train_data)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # generate lattices, go to equilibrium, and average couplers\n",
    "            self.generate_lattices()\n",
    "            self.equilibrium(flips_per_site=flips_per_site)\n",
    "            model_coupler_avg = avg_coupler(self.lattices)\n",
    "\n",
    "            # update weights \n",
    "            self.weights = self.weights + learning_rate * (train_coupler_avg[1] - model_coupler_avg[1])\n",
    "\n",
    "            # we know weights can't be more than 1 or less than -1 so put a hard stop\n",
    "            self.weights[np.where(self.weights > 1)] = 1.\n",
    "            self.weights[np.where(self.weights < -1)] = -1. \n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Current KL is {self._KL(train_data):.2f} and weights are: {self.weights}\")\n",
    "\n",
    "\n",
    "        final_weights = {}\n",
    "\n",
    "        for j in range(self.lattices.shape[1]):\n",
    "            if j != self.lattices.shape[1] - 1:\n",
    "                final_weights[(j, j+1)] = self.weights[j]\n",
    "            else:\n",
    "                final_weights[(j, 0)] = self.weights[j]\n",
    "\n",
    "        print('Final weights: ', final_weights)\n",
    "\n",
    "    def _KL(self, train_data):\n",
    "        '''\n",
    "        tracks KL divergence by estimating probability using number of occurences\n",
    "        divided by total number of lattices\n",
    "        '''\n",
    "        # find number of unique instances in data and current lattices\n",
    "        data_instances = []\n",
    "        model_instances = []\n",
    "\n",
    "        # collect all unique lattices in data\n",
    "        for i in range(train_data.shape[0]):\n",
    "            if train_data[i].tolist() not in data_instances:\n",
    "                data_instances.append(train_data[i].tolist())\n",
    "\n",
    "        #collect all unique lattices in model\n",
    "        for i in range(self.lattices.shape[0]):\n",
    "            if self.lattices[i].tolist() not in model_instances:\n",
    "                model_instances.append(self.lattices[i].tolist())\n",
    "\n",
    "        # now calcualte KL\n",
    "        KL = 0\n",
    "        for instance in model_instances:\n",
    "            if instance in data_instances:\n",
    "                p_data = self._p(pm_data, instance)\n",
    "                p_model = self._p(self.lattices, instance)\n",
    "                KL +=  p_data * np.log(p_data/p_model)\n",
    "        return KL\n",
    "\n",
    "    def _p(self, data, instance):\n",
    "        '''Estimates probability of configuration based on number of exact instances in dataset'''\n",
    "        num_equal = 0\n",
    "        for lattice in data:\n",
    "            if np.array_equal(lattice, instance): num_equal += 1\n",
    "\n",
    "        return num_equal/data.shape[0]\n",
    "\n",
    "ising = Ising1D(pm_data.shape[1], pm_data.shape[0])\n",
    "ising.train_weights(pm_data, 250, 0.05, flips_per_site=25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4232523723575745"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_sum = 0\n",
    "# for i in range(pm_data.shape[0]):\n",
    "#     for j in range(pm_data.shape[1]):\n",
    "#         print()\n",
    "\n",
    "def p(data, config):\n",
    "    '''Estimates probability of configuration based on number of exact configs in dataset'''\n",
    "    num_equal = 0\n",
    "    for lattice in data:\n",
    "        if np.array_equal(lattice, config): num_equal += 1\n",
    "\n",
    "    return num_equal/data.shape[0]\n",
    "\n",
    "data_instances = []\n",
    "model_instances = []\n",
    "\n",
    "# collect all unique lattices in data\n",
    "for i in range(pm_data.shape[0]):\n",
    "    if pm_data[i].tolist() not in data_instances:\n",
    "        data_instances.append(pm_data[i].tolist())\n",
    "\n",
    "#collect all unique lattices in model\n",
    "for i in range(pm_data.shape[0]):\n",
    "    if ising.lattices[i].tolist() not in model_instances:\n",
    "        model_instances.append(ising.lattices[i].tolist())\n",
    "\n",
    "# loop through all shared instances calcualting KL\n",
    "KL = 0\n",
    "for instance in data_instances:\n",
    "    if instance in model_instances:\n",
    "        p_data = p(pm_data, instance)\n",
    "        p_model = p(ising.lattices, instance)\n",
    "        KL +=  p_data * np.log(p_data/p_model)\n",
    "\n",
    "KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm_data[1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21e3e09130b141b1946ff20fc683d5b9b11c33d8db188a55f69210dd31c5f84c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
